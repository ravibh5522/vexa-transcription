FROM nvidia/cuda:12.3.2-cudnn9-runtime-ubuntu22.04

# Set DEBIAN_FRONTEND to noninteractive to avoid prompts during apt-get install
ENV DEBIAN_FRONTEND=noninteractive

# Set environment variables
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1

# Install system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3 \
    python3-pip \
    libsndfile1 \
    ffmpeg \
    wget \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Install faster-whisper first
RUN pip3 install faster-whisper

# Install PyTorch compatible with CUDA 11.8
RUN python3 -m pip install --no-cache-dir torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Set working directory
WORKDIR /app

# Copy only the requirements file first
COPY services/WhisperLive/requirements/server.txt /tmp/requirements.txt

# Remove openai-whisper and onnxruntime lines from the copied requirements file
RUN sed -i '/openai-whisper/d' /tmp/requirements.txt || true \
    && sed -i '/onnxruntime==/d' /tmp/requirements.txt || true

# Install remaining Python dependencies from the modified requirements file
RUN python3 -m pip install --no-cache-dir -r /tmp/requirements.txt

# Now copy the application code
COPY services/WhisperLive/ /app/

# Copy our entrypoint script
COPY services/WhisperLive/entrypoint.sh /entrypoint.sh
RUN chmod +x /entrypoint.sh

# Copy healthcheck script
COPY services/WhisperLive/healthcheck.sh /healthcheck.sh
RUN chmod +x /healthcheck.sh

# Set it as the entrypoint
ENTRYPOINT ["/entrypoint.sh"]

# Default command to run the server with faster_whisper backend
CMD ["--port", "9090", "--backend", "faster_whisper"]

# Define the health check using the script
HEALTHCHECK --interval=15s --timeout=5s --start-period=60s --retries=3 CMD /healthcheck.sh